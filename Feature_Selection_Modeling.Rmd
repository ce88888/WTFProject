---
title: "FeatureSelection & Modeling"
author: "Team Strikes"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
  code_folding: hide
  highlight: pygment
  theme: united
---
  
  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, dpi=100)
```

```{r Check installed packages, echo = FALSE, warning=FALSE, message=FALSE}

# Creating a vector of packages used within
packages <- c(
  'tidyverse',
  'data.table',
  'scales',
  'magrittr',
  'tidyselect',
  'lubridate',
  'zoo',
  'VIM',
  'psych',
  'MASS',
  'varrank',
  'proxy',
  'caret',
  'randomForest',
  'mlbench',
  'pROC',
  'e1071',
  'DMwR',
  'caTools',
  'ROCR',
  'lares',
  'klaR',
  'MLeval',
  'splitstackshape',
  'Boruta',
  'mctest',
  'Information',
  'pastecs'
)

# Checking for package installations on the system and installing if not found
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}

# Including the packages for use
for (package in packages) {
  library(package, character.only = TRUE)
}

```

```{r}
# Read dataset from RDS
model.data <- readRDS("KDEN_FINAL.RDS")

head(model.data)
```

```{r}
summary(model.data[3:12])
```


```{r}

# Add Year, Month, Day and Weekday fields to  the dataset as factors
# Bind new cols to the original dataset
  model.data <- cbind(
    model.data,
    data.frame(
      YEAR = as.factor(format(model.data$DATE, format = "%Y")),
      MONTH = as.factor(format(model.data$DATE, format = "%m")),
      DAY = as.factor(format(model.data$DATE, format = "%d")),
      WEEKOFDAY = as.factor(format(model.data$DATE, format = "%V"))
    )
  )

# Remove AirportId and Date columns -- to do put column names
model.data <-
  subset(model.data, select = -c(`AIRPORT ID`, DATE, ARRIVALS, DEPARTURES))

# Rename Windangle and windspeed
model.data <-
  model.data %>% dplyr::rename(WANGLE = `WIND ANGLE`,
                               WSPEED = `WIND SPEED`)

# Because of memory constraints considering only 2 years data
model.data <- model.data %>% filter(model.data$YEAR %in% c(2014,2015,2016,2017,2018))

# Converting target as a factor
model.data$STRIKE <- as.factor(model.data$STRIKE)
```

```{r}
# Run this on the original dataset
# clusterKmeans(model.data, k=5, limit = 5, ohse = TRUE, norm = TRUE, seed = 1234)
```

```{r}

years.list <- c(2014, 2015, 2016, 2017, 2018)

for (year in years.list) {
  set.seed(42)  # good idea to set the random seed for reproducibility
  temp.data <- model.data %>% filter(model.data$YEAR == year)
  temp.0.data <- temp.data %>% filter(temp.data$STRIKE == 0)
  temp.1.data <- temp.data %>% filter(temp.data$STRIKE == 1)
  sample.0.data <- stratified(temp.0.data, c('STRIKE'), 0.02)
  sample.1.data <- stratified(temp.1.data, c('STRIKE'), 0.4)
  sample.data <- rbind(sample.0.data, sample.1.data)
  if (year == 2014) {
    strikes.data <- sample.data
  }
  else{
    strikes.data <- bind_rows(strikes.data, sample.data)
  }
}

rm(temp.0.data, temp.1.data, temp.data, sample.0.data, sample.1.data, sample.data)
```



```{r}
corr.data <-
  strikes.data %>% dplyr::select(STRIKE,
                                    WANGLE,
                                    WSPEED,
                                    TEMP,
                                    CLOUDH,
                                    COVER,
                                    COVERH,
                                    BIRDCOUNT,
                                    TOTAL,
                                    SLP,
                                    VIS,
                                    PRECIP
                                    # RTIME,
                                    # MONTH,
                                    # DAY
                                    )

corr_cross(corr.data)
```



```{r}
# Use Random Forest variable importance technique for variable selection
# The below list has been tailored after multiple iterations
fit <- randomForest::randomForest(
  as.factor(STRIKE) ~ .,
  data = strikes.data,
  importance = TRUE,
  proximity = FALSE,
)
importance(fit)

varImp(fit)
varImpPlot(fit, type = 2)
importanceOrder = order(-fit$importance)

names <- rownames(fit$importance)
names
```

```{r}
# fit <- randomForest::randomForest(
#   as.factor(STRIKE) ~ .,
#   data = downsample.data,
#   importance = TRUE,
#   proximity = TRUE,
# )
# importance(fit)
# 
# varImp(fit)
# varImpPlot(fit, type = 2)
# importanceOrder = order(-fit$importance)
# 
# names <- rownames(fit$importance)
# names
```

```{r}

var.boruta <-
  Boruta(
    as.factor(STRIKE) ~ WANGLE + WSPEED + TEMP + COVER + BIRDCOUNT + TOTAL + SLP + VIS + PRECIP + RTIME + MONTH + DAY + RTIME + WEEKOFDAY,
    data = sample.data
  )
print(var.boruta)
plot(var.boruta, cex.axis = 0.8, las = 1)
```


```{r}

# prepare training scheme
control <- trainControl(method = "cv", number = 2)

# train the model
model <- train(STRIKE~., data = strikes.data, method = "lvq", preProcess = "scale", trControl = control)

# estimate variable importance
importance <- varImp(model, useModel = FALSE)

# summarize importance
print(importance)

# plot importance
plot(importance)
```

```{r}
# Helper function for VIF
VIF <-
  function(linear.model,
           no.intercept = FALSE,
           all.diagnostics = FALSE,
           plot = FALSE) {
    if (no.intercept == FALSE)
      design.matrix <- model.matrix(linear.model)[, -1]
    if (no.intercept == TRUE)
      design.matrix <- model.matrix(linear.model)
    if (plot == TRUE)
      mc.plot(design.matrix, linear.model$model[1])
    if (all.diagnostics == FALSE)
      output <-
        imcdiag(design.matrix,
                linear.model$model[1],
                method = 'VIF')$idiags[, 1]
    if (all.diagnostics == TRUE)
      output <-
        imcdiag(design.matrix, linear.model$model[1])
    output
  }

```

```{r}
set.seed(123)
strikes.sample <-
  strikes.data[, c(
    "STRIKE",
    "WANGLE",
    "WSPEED",
    "TEMP",
    "COVER",
    "BIRDCOUNT",
    "TOTAL",
    "SLP",
    "VIS",
    "PRECIP",
    "CLOUDH",
    "COVERH"
  )]

strikes.sample$STRIKE <- as.numeric(strikes.sample$STRIKE)

# strikes.sample[, 2:12] <- scale(strikes.sample[, 2:12])

fit <- glm(STRIKE ~ ., data = strikes.sample)
VIF(fit, all.diagnostics = TRUE, plot = TRUE)

```


```{r}

# strikes.cat <-
#   model.data[, c("RTIME", "MONTH", "WEEKOFDAY", "STRIKE")]
# 
# ### Ranking variables using penalized IV
# info.val.data <-
#   create_infotables(data = strikes.cat, y = as.numeric(strikes.cat$STRIKE), parallel = TRUE)
# 
# info.val = data.frame(info.val.data$Summary)
# info.val.data$Summary

nzv <- nearZeroVar(strikes.data, saveMetrics = TRUE)
nzv[nzv[,"zeroVar"] > 0, ] # Check for zero variance predictors. None
nzv[nzv[,"zeroVar"] + nzv[,"nzv"] > 0, ] # Check for near-zero variance predictors

```



```{r}
# SMOTE oversampling for Classification 
upsample.data <-
  SMOTE(
    STRIKE ~  WSPEED + TEMP + BIRDCOUNT + TOTAL + COVER + RTIME + MONTH,
    strikes.data,
    perc.over = 2000,
    k = 10
  )

upsample.data <- strikes.data %>% dplyr::select(STRIKE,
                                                 WSPEED,
                                                 TEMP,
                                                 BIRDCOUNT,
                                                 TOTAL,
                                                 COVER,
                                                 RTIME,
                                                 WEEKOFDAY,
                                                 MONTH)

upsample.data <- upsample.data %>%
  mutate(STRIKE = ifelse(STRIKE == 0, "NO", "YES"))

```

```{r}
describe(upsample.data)
```


```{r}
downsample.data <-
  SMOTE(
    STRIKE ~ WSPEED + TEMP + BIRDCOUNT + TOTAL + COVER + RTIME + MONTH,
    model.data,
    perc.under = 2900,
    k = 10
  )

downsample.data <- strikes.data %>% dplyr::select(STRIKE,
                                                 WSPEED,
                                                 TEMP,
                                                 BIRDCOUNT,
                                                 TOTAL,
                                                 COVER,
                                                 RTIME,
                                                 WEEKOFDAY,
                                                 MONTH)

downsample.data <- downsample.data %>%
  mutate(STRIKE = ifelse(STRIKE == 0, "NO", "YES"))
```

```{r}
describe(downsample.data)
```


```{r}
# Create the training and test datasets
set.seed(100)

# Step 1: Get row numbers for the training data
trainRowNumbers.up <-
  createDataPartition(upsample.data$STRIKE, p = 0.8, list = FALSE)

# Step 2: Create the training  dataset
train.up.data <- upsample.data[trainRowNumbers.up, ]

# Step 3: Create the test dataset
test.up.data <- upsample.data[-trainRowNumbers.up, ]

```

```{r}
# Create the training and test datasets
set.seed(1234)

# Step 1: Get row numbers for the training data
trainRowNumbers.dn <-
  createDataPartition(downsample.data$STRIKE, p = 0.8, list = FALSE)

# Step 2: Create the training  dataset
train.dn.data <- downsample.data[trainRowNumbers.dn, ]

# Step 3: Create the test dataset
test.dn.data <- downsample.data[-trainRowNumbers.dn, ]

```


```{r}

# 5 Fold cross validation with Probabilities
tc <- trainControl(
  method = "cv",
  number = 5,
  savePredictions = "final",
  classProbs = TRUE,
  verboseIter = TRUE,
  summaryFunction = twoClassSummary
)
```

```{r}
validateAndPrintResult <- function(model, test.data) {
  # Summarise Results
  print(model)
  
  ## run MLeval
  res <- evalm(model)
  
  # Predict on testData
  predicted.resp <- predict(model, test.data)
  head(predicted.resp)
  
  # Compute the confusion matrix
  confusionMatrix(
    reference = as.factor(test.data$STRIKE),
    data = predicted.resp,
    mode = 'everything',
    positive = 'YES'
  )
}
```

```{r}


# To Do - remove the indexes and add in variable names
runModel <- function(train.data, method.name) {
  caret::train(
    train.data[, c("WSPEED",
                   "TEMP",
                   "BIRDCOUNT",
                   "TOTAL",
                   "COVER",
                   "RTIME",
                   "WEEKOFDAY",
                   "MONTH")],
    train.data[, c("STRIKE")],
    data = train.data,
    tuneLength = 5,
    method = method.name,
    metric = 'ROC',
    trControl = tc,
    preProcess = c("center", "scale")
  )
}

```


```{r message=FALSE, warning=FALSE}

# Fit Naive Bayes Model for upsampled data
model.nb.up <- runModel(train.up.data, "nb")

validateAndPrintResult(model.nb.up, test.up.data)

```


```{r message=FALSE, warning=FALSE}
# Fit Naive Bayes Model with downsampled data
model.nb.down <- runModel(train.dn.data, "nb")

validateAndPrintResult(model.nb.down, test.dn.data)

```

```{r}
# Fit Random Forest Model with upsampled data
model.up.rf <- runModel(train.up.data, "rf")

validateAndPrintResult(model.up.rf, test.up.data)
```

```{r}
# Fit Random Forest Model with down sampled data
model.dn.rf <- runModel(train.dn.data, "rf")

validateAndPrintResult(model.dn.rf, test.dn.data)
```




```{r}
# Compare model performances using resample()
models_compare <-
  resamples(
    list(
      NB_UP = model.nb.up,
      # NB_DN = model.nb.down,
      RF_UP = model.up.rf
      # RF_DOWN = model.dn.rf
      # SVM_UP = model.up.svm,
      # SVM_DN = model.dn.svm
    )
  )

# Summary of the models performances
summary(models_compare)
```

```{r}
# Draw box plots to compare models
scales <- list(x = list(relation = "free"),
               y = list(relation = "free"))
bwplot(models_compare, scales = 'free', layout = c(1,1))
```


```{r}
 
model <-
  glm (
    as.factor(STRIKE) ~  WSPEED + TEMP + COVER + TOTAL + RTIME + MONTH,
    data = train.up.data,
    family = binomial
  )
summary(model)
```
```{r}
## Predict the Values
predict <- predict(model, test.up.data, type = 'response')

## Create Confusion Matrix
table(test.up.data$STRIKE, predict > 0.009)

# ROC Curve
ROCRpred <- prediction(predict, test.up.data$STRIKE)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))
ROCRperf

# # Predict using test data and generate confusion matrix
# predicted.response <- predict(model, test.up.data, )
# confusionMatrix(data = as.factor(predicted.response), reference = test.up.data$STRIKE)
# 
# predicted.response
summary(model) # Summary of model
cmLR <- table(predict>0.01, test.up.data$STRIKE)
cmLR # Confusion matrix
errorLR <- 100*(1-sum(diag(cmLR))/sum(cmLR))
errorLR # error rate
accuracyLR <- 100 - errorLR
accuracyLR # accuracy rate
precisionLR <- 100*cmLR[2,2]/sum(cmLR[2,1],cmLR[2,2]) 
precisionLR # precision
recallLR <- 100*cmLR[2,2]/sum(cmLR[1,2],cmLR[2,2]) 
recallLR # recall
FscoreLR <- 2*precisionLR*recallLR/(precisionLR+recallLR)
FscoreLR # F-score
```
